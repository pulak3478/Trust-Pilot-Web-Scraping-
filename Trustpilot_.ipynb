{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90geyfs0aLWU"
      },
      "outputs": [],
      "source": [
        "from time import sleep\n",
        "import requests\n",
        "\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def soup2list(src, list_, attr=None):\n",
        "    if attr:\n",
        "        for val in src:\n",
        "            list_.append(val[attr])\n",
        "    else:\n",
        "        for val in src:\n",
        "            list_.append(val.get_text())\n",
        "\n",
        "users = []\n",
        "userReviewNum = []\n",
        "ratings = []\n",
        "locations = []\n",
        "dates = []\n",
        "reviews = []\n",
        "\n",
        "from_page = 851\n",
        "to_page = 900\n",
        "company = 'flashbay.com'\n",
        "\n",
        "\n",
        "headers = requests.utils.default_headers()\n",
        "headers.update({\n",
        "    'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0',\n",
        "})\n",
        "\n",
        "reddit1Link = requests.get(\"https://www.reddit.com/r/tensorflow/comments/650p49/question_im_a_techy_35_year_old_and_i_think_ai_is/\", headers=headers)\n",
        "reddit1Content =BeautifulSoup(reddit1Link.content,\"lxml\")\n",
        "print(reddit1Content)\n",
        "for i in range(from_page, to_page+1):\n",
        "\n",
        "   result = requests.get(fr\"https://www.trustpilot.com/review/{company}?page={i}\")\n",
        "   soup = BeautifulSoup(result.content)\n",
        "\n",
        "   # Trust Pilot was setup in a way that's not friendly to scraping, so this hacky method will do.\n",
        "   soup2list(soup.find_all('span', {'class','typography_heading-xxs__QKBS8 typography_appearance-default__AAY17'}), users)\n",
        "   soup2list(soup.find_all('div', {'class','typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l styles_detailsIcon__Fo_ua'}), locations)\n",
        "   soup2list(soup.find_all('span', {'class','typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l'}), userReviewNum)\n",
        "   soup2list(soup.find_all('div', {'class','styles_reviewHeader__iU9Px'}), dates)\n",
        "   soup2list(soup.find_all('div', {'class','styles_reviewHeader__iU9Px'}), ratings, attr='data-service-review-rating')\n",
        "   soup2list(soup.find_all('div', {'class','styles_reviewContent__0Q2Tg'}), reviews)\n",
        "\n",
        "   # To avoid throttling\n",
        "   sleep(1)\n",
        "\n",
        "review_data = pd.DataFrame(\n",
        "{\n",
        "   'Username':users,\n",
        "   'Total reviews':userReviewNum,\n",
        "   'location':locations,\n",
        "   'date':dates,\n",
        "   'content':reviews,\n",
        "   'Rating': ratings\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(review_data )"
      ],
      "metadata": {
        "id": "f7gMdetEaOYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "csv_file_path = '/content/drive/MyDrive/Flashbay(851-900).csv'\n",
        "\n",
        "# Use the to_csv method to save the DataFrame to a CSV file\n",
        "review_data.to_csv(csv_file_path, index=False)\n",
        "\n",
        "# Print a message to confirm that the CSV file has been saved\n",
        "print(f'Data has been saved to {csv_file_path}')"
      ],
      "metadata": {
        "id": "tTLaeohjaRSZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}